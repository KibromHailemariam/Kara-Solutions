{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data scraping and collection pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telegram Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authenticate with Telegram API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signed in successfully as Kibrom; remember to not break the ToS or you will risk an account ban!\n",
      "Client Authenticated\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "from telethon import TelegramClient\n",
    "\n",
    "# Apply fix for nested event loops\n",
    "nest_asyncio.apply()\n",
    "\n",
    "api_id = 25116412  \n",
    "api_hash = \"3d271d7445279596e83ea75d79ff760d\"\n",
    "phone_number = \"+251985535012\"\n",
    "\n",
    "client = TelegramClient(\"session_name\", api_id, api_hash)\n",
    "\n",
    "async def main():\n",
    "    await client.start(phone_number)\n",
    "    print(\"Client Authenticated\")\n",
    "\n",
    "# Run the async function safely\n",
    "await main()  # Works inside Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape Data from Telegram Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped data from 5 channels and saved to 'telegram_raw_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "from telethon import functions, types\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'client' is already defined and started from your previous code\n",
    "# Make sure 'client' is in the global scope or you pass it to functions properly\n",
    "\n",
    "# Define scrape_channel function\n",
    "async def scrape_channel(channel_username, client):\n",
    "    try:\n",
    "        channel = await client.get_entity(channel_username)\n",
    "        messages = await client.get_messages(channel, limit=100)  # Adjust limit as needed\n",
    "        data = []\n",
    "        \n",
    "        for message in messages:\n",
    "            data.append({\n",
    "                'date': message.date,\n",
    "                'text': message.text if message.text else None,\n",
    "                'media_type': type(message.media).__name__ if message.media else None,\n",
    "            })\n",
    "        \n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping channel {channel_username}: {e}\")\n",
    "        return []\n",
    "\n",
    "# List of channels to scrape\n",
    "channels = ['DoctorsET', 'Chemed', 'lobelia4cosmetics', 'yetenaweg', 'EAHCI']\n",
    "\n",
    "# Scrape data from all channels\n",
    "async def scrape_all_channels(client):\n",
    "    all_data = []\n",
    "    \n",
    "    for channel in channels:\n",
    "        scraped_data = await scrape_channel(channel, client)\n",
    "        all_data.extend(scraped_data)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(all_data)\n",
    "\n",
    "    # Save to CSV\n",
    "    df.to_csv('telegram_raw_data.csv', index=False)\n",
    "    print(f\"Scraped data from {len(channels)} channels and saved to 'telegram_raw_data.csv'.\")\n",
    "\n",
    "# Run the scraping function\n",
    "# Make sure 'client' is accessible here\n",
    "await scrape_all_channels(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Scraping for Object Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "async def download_images(channel_username, save_dir):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    channel = await client.get_entity(channel_username)\n",
    "    messages = await client.get_messages(channel, limit=50)  # Adjust limit as needed\n",
    "    \n",
    "    for i, message in enumerate(messages):\n",
    "        if message.media:\n",
    "            await message.download_media(file=os.path.join(save_dir, f'image_{i}.jpg'))\n",
    "\n",
    "# Example: Download images from a channel\n",
    "channel_username = 'lobelia4cosmetics'\n",
    "save_directory = 'downloaded_images'\n",
    "client.loop.run_until_complete(download_images(channel_username, save_directory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving to Local Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming data is already in a DataFrame\n",
    "df = pd.read_csv('telegram_raw_data.csv')\n",
    "\n",
    "conn = sqlite3.connect('telegram_data.db')\n",
    "df.to_sql('raw_messages', conn, if_exists='replace', index=False)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring and Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file will be created at: ../notebooks\\telegram_scraping_log_20250131_182257.log\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Define the log file path explicitly\n",
    "log_file_path = os.path.join('../notebooks', 'telegram_scraping_log_{}.log'.format(datetime.now().strftime('%Y%m%d_%H%M%S')))\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename=log_file_path,\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "# Print the log file path for debugging\n",
    "print(\"Log file will be created at:\", log_file_path)\n",
    "\n",
    "# Example usage in your scraping script\n",
    "try:\n",
    "    # Your scraping code here\n",
    "    channel_name = 'DoctorsET'  # Example channel name\n",
    "    logging.info('Scraping started for channel: %s', channel_name)\n",
    "    # Simulate an error for testing\n",
    "    # raise Exception(\"Test error\")\n",
    "except Exception as e:\n",
    "    logging.error('Error occurred while scraping: %s', str(e))\n",
    "finally:\n",
    "    logging.info('Scraping process concluded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
