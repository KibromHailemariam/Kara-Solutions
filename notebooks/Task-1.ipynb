{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data scraping and collection pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telegram Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authenticate with Telegram API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signed in successfully as nav; remember to not break the ToS or you will risk an account ban!\n",
      "Client Created\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from telethon import TelegramClient\n",
    "\n",
    "# Replace these with your own API credentials from https://my.telegram.org\n",
    "api_id = '21423729'\n",
    "api_hash = '60c830a40a5ff9cb549824b9a6399737'\n",
    "phone_number = '+251986408483'\n",
    "\n",
    "# Create the client\n",
    "client = TelegramClient('session_name', api_id, api_hash)\n",
    "\n",
    "async def main():\n",
    "    await client.start(phone_number)\n",
    "    print(\"Client Created\")\n",
    "\n",
    "# Use the existing event loop in Jupyter Notebook\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape Data from Telegram Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped data from 5 channels and saved to 'telegram_raw_data.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zelalemtegene/envs/shared_env/lib/python3.9/site-packages/telethon/extensions/binaryreader.py:37: RuntimeWarning: coroutine 'main' was never awaited\n",
      "  return int.from_bytes(self.read(4), byteorder='little', signed=signed)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "from telethon import functions, types\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'client' is already defined and started from your previous code\n",
    "# Make sure 'client' is in the global scope or you pass it to functions properly\n",
    "\n",
    "# Define scrape_channel function\n",
    "async def scrape_channel(channel_username, client):\n",
    "    try:\n",
    "        channel = await client.get_entity(channel_username)\n",
    "        messages = await client.get_messages(channel, limit=100)  # Adjust limit as needed\n",
    "        data = []\n",
    "        \n",
    "        for message in messages:\n",
    "            data.append({\n",
    "                'date': message.date,\n",
    "                'text': message.text if message.text else None,\n",
    "                'media_type': type(message.media).__name__ if message.media else None,\n",
    "            })\n",
    "        \n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping channel {channel_username}: {e}\")\n",
    "        return []\n",
    "\n",
    "# List of channels to scrape\n",
    "channels = ['DoctorsET', 'Chemed', 'lobelia4cosmetics', 'yetenaweg', 'EAHCI']\n",
    "\n",
    "# Scrape data from all channels\n",
    "async def scrape_all_channels(client):\n",
    "    all_data = []\n",
    "    \n",
    "    for channel in channels:\n",
    "        scraped_data = await scrape_channel(channel, client)\n",
    "        all_data.extend(scraped_data)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(all_data)\n",
    "\n",
    "    # Save to CSV\n",
    "    df.to_csv('telegram_raw_data.csv', index=False)\n",
    "    print(f\"Scraped data from {len(channels)} channels and saved to 'telegram_raw_data.csv'.\")\n",
    "\n",
    "# Run the scraping function\n",
    "# Make sure 'client' is accessible here\n",
    "await scrape_all_channels(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Scraping for Object Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def download_images(channel_username, save_dir):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    channel = await client.get_entity(channel_username)\n",
    "    messages = await client.get_messages(channel, limit=50)  # Adjust limit as needed\n",
    "    \n",
    "    for i, message in enumerate(messages):\n",
    "        if message.media:\n",
    "            await message.download_media(file=os.path.join(save_dir, f'image_{i}.jpg'))\n",
    "\n",
    "# Example: Download images from a channel\n",
    "channel_username = 'lobelia4cosmetics'\n",
    "save_directory = 'downloaded_images'\n",
    "client.loop.run_until_complete(download_images(channel_username, save_directory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving to Local Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming data is already in a DataFrame\n",
    "df = pd.read_csv('telegram_raw_data.csv')\n",
    "\n",
    "conn = sqlite3.connect('telegram_data.db')\n",
    "df.to_sql('raw_messages', conn, if_exists='replace', index=False)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring and Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename='telegram_scraping_log_{}.log'.format(datetime.now().strftime('%Y%m%d_%H%M%S')),\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "# Example usage in your scraping script\n",
    "try:\n",
    "    # Your scraping code here\n",
    "    logging.info('Scraping started for channel: %s', channel_name)\n",
    "    # More logging statements as needed\n",
    "except Exception as e:\n",
    "    logging.error('Error occurred while scraping: %s', str(e))\n",
    "finally:\n",
    "    logging.info('Scraping process concluded')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shared_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
